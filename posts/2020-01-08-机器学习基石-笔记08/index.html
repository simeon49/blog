<!DOCTYPE html>
<html lang="zh-Hans-CN">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		
		<meta name="author" content="Simeon">
		<meta name="description" content="Simeon 个人微博">
		<meta name="generator" content="Hugo 0.52" />
		<title>机器学习基石-笔记08 &middot; Simeon&#39;s blog</title>
		<link rel="shortcut icon" href="https://simeon49.github.io/blog/images/favicon.ico">
		<link rel="stylesheet" href="https://simeon49.github.io/blog/css/style.css">
		<link rel="stylesheet" href="https://simeon49.github.io/blog/css/highlight.css">

		
		<link rel="stylesheet" href="https://simeon49.github.io/blog/css/font-awesome.min.css">
		

		

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='https://simeon49.github.io/blog/'> <span class="arrow">←</span>Home</a>
	
	<a href='https://simeon49.github.io/blog/posts'>Archive</a>
	<a href='https://simeon49.github.io/blog/tags'>Tags</a>
	<a href='https://simeon49.github.io/blog/categories'>Categories</a>
	<a href='https://simeon49.github.io/blog/about'>About</a>

	

	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        机器学习基石-笔记08
                    </h1>
                    <h2 class="headline">
                    Jan 8, 2020 00:00
                    · 2047 words
                    · 5 minute read
                      <span class="tags">
                      
                      
                          
                              <a href="https://simeon49.github.io/blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
                          
                              <a href="https://simeon49.github.io/blog/tags/ml">ML</a>
                          
                      
                      
                      </span>
                    </h2>
                </header>
                
                <section id="post-body">
                    

<p>NTU林轩田的《机器学习基石》课程笔记(转载) <br>
&hellip;</p>

<h1 id="8-noise-and-error">8 &ndash; Noise and Error</h1>

<p>上一节课，我们主要介绍了VC Dimension的概念。如果Hypotheses set的VC Dimension是有限的，且有足够多N的资料，同时能够找到一个hypothesis使它的<img src="../../pic/ML/3f9b919897da6adfb854d4b7516bde39.jpg" alt="" />，那么就能说明机器学习是可行的。本节课主要讲了数据集有Noise的情况下，是否能够进行机器学习，并且介绍了假设空间H下演算法A的Error估计。</p>

<h3 id="一-noise-and-probablistic-target"><strong>一、Noise and Probablistic target</strong></h3>

<p>上节课推导VC Dimension的数据集是在没有Noise的情况下，本节课讨论如果数据集本身存在Noise，那VC Dimension的推导是否还成立呢？</p>

<p>首先，Data Sets的Noise一般有三种情况：</p>

<ul>
<li><p><strong>由于人为因素，正类被误分为负类，或者负类被误分为正类；</strong></p></li>

<li><p><strong>同样特征的样本被模型分为不同的类；</strong></p></li>

<li><p><strong>样本的特征被错误记录和使用。</strong></p></li>
</ul>

<p><img src="../../pic/ML/4c9a1892e76d6e495adf33ea3aefa6f8.jpg" alt="这里写图片描述" /></p>

<p>之前的数据集是确定的，即没有Noise的，我们称之为Deterministic。现在有Noise了，也就是说在某点处不再是确定分布，而是概率分布了，即对每个(x，y)出现的概率是<img src="../../pic/ML/12d12c819c2467c289e4a700f3623212.jpg" alt="" />。</p>

<p>因为Noise的存在，比如在x点，有0.7的概率y=1，有0.3的概率y=0，即y是按照<img src="../../pic/ML/12d12c819c2467c289e4a700f3623212.jpg" alt="" />分布的。数学上可以证明如果数据集按照<img src="../../pic/ML/12d12c819c2467c289e4a700f3623212.jpg" alt="" />概率分布且是iid的，那么以前证明机器可以学习的方法依然奏效，VC Dimension有限即可推断<img src="../../pic/ML/719cb690171fbdd7415aa6085c0b4b68.jpg" alt="" />和<img src="../../pic/ML/6bbd5053ee6227f783df8773f0f9264a.jpg" alt="" />是近似的。</p>

<p><img src="../../pic/ML/66c7bf35e055d26d9d4d717c9a551baf.jpg" alt="这里写图片描述" /></p>

<p><img src="../../pic/ML/12d12c819c2467c289e4a700f3623212.jpg" alt="" />称之为目标分布（Target Distribution）。它实际上告诉我们最好的选择是什么，同时伴随着多少noise。其实，没有noise的数据仍然可以看成“特殊”的<img src="../../pic/ML/12d12c819c2467c289e4a700f3623212.jpg" alt="" />概率分布，即概率仅是1和0.对于以前确定的数据集：</p>

<p><img src="../../pic/ML/e02323671eeb29acd0c899755082c731.jpg" alt="这里写图片描述" /></p>

<p>在引入noise的情况下，新的学习流程图如下所示：</p>

<p><img src="../../pic/ML/42294271589ff348f2f12ae827fc9e1a.jpg" alt="这里写图片描述" /></p>

<h3 id="二-error-measure"><strong>二、ERROR Measure</strong></h3>

<p>机器学习需要考虑的问题是找出的矩g与目标函数f有多相近，我们一直使用<img src="../../pic/ML/6351a210e7296714df1442ef4e184cec.jpg" alt="" />进行误差的估计，那一般的错误测量有哪些形式呢？</p>

<p>我们介绍的矩g对错误的衡量有三个特性：</p>

<ul>
<li><p><strong>out-of-sample：样本外的未知数据</strong></p></li>

<li><p><strong>pointwise：对每个数据点x进行测试</strong></p></li>

<li><p><strong>classification：看prediction与target是否一致，classification error通常称为0/1 error</strong></p></li>
</ul>

<p><img src="../../pic/ML/3f229952e5a8f34c47b6589210f89d64.jpg" alt="这里写图片描述" /></p>

<p>PointWise error实际上就是对数据集的每个点计算错误并计算平均，<img src="../../pic/ML/719cb690171fbdd7415aa6085c0b4b68.jpg" alt="" />和<img src="../../pic/ML/6bbd5053ee6227f783df8773f0f9264a.jpg" alt="" />的pointwise error的表达式为：</p>

<p><img src="../../pic/ML/957e433a36b59985b512793f0428cf4f.jpg" alt="这里写图片描述" /></p>

<p>pointwise error是机器学习中最常用也是最简单的一种错误衡量方式，未来课程中，我们主要考虑这种方式。pointwise error一般可以分成两类：0/1 error和squared error。0/1 error通常用在分类（classification）问题上，而squared error通常用在回归（regression）问题上。</p>

<p><img src="../../pic/ML/f731d065e6e70a4fdce5f1e4c5d4d595.jpg" alt="这里写图片描述" /></p>

<p>Ideal Mini-Target由<img src="../../pic/ML/12d12c819c2467c289e4a700f3623212.jpg" alt="" />和err共同决定，0/1 error和squared error的Ideal Mini-Target计算方法不一样。例如下面这个例子，分别用0/1 error和squared error来估计最理想的mini-target是多少。0/1 error中的mini-target是取P(y|x)最大的那个类，而squared error中的mini-target是取所有类的加权平方和。</p>

<p><img src="../../pic/ML/b0662d287b1cc9bcb80e114c28395d35.jpg" alt="这里写图片描述" /></p>

<p>有了错误衡量，就会知道当前的矩g是好还是不好，并会让演算法不断修正，得到更好的矩g，从而使得g与目标函数更接近。所以，引入error measure后，学习流程图如下所示：</p>

<p><img src="../../pic/ML/b128d02e9f95b0547a0fc9a18f917da1.jpg" alt="这里写图片描述" /></p>

<h3 id="三-algorithmic-error-measure"><strong>三、Algorithmic Error Measure</strong></h3>

<p>Error有两种：false accept和false reject。false accept意思是误把负类当成正类，false reject是误把正类当成负类。 根据不同的机器学习问题，false accept和false reject应该有不同的权重，这根实际情况是符合的，比如是超市优惠，那么false reject应该设的大一些；如果是安保系统，那么false accept应该设的大一些。</p>

<p><img src="../../pic/ML/974807506c5372a2b9f110fbdc400d3a.jpg" alt="这里写图片描述" /></p>

<p>机器学习演算法A的cost function error估计有多种方法，真实的err一般难以计算，常用的方法可以采用plausible或者friendly，根据具体情况而定。</p>

<p><img src="../../pic/ML/025babd803f88f4853938e41e8a8760b.jpg" alt="这里写图片描述" /></p>

<p>引入algorithm error measure之后，学习流程图如下：</p>

<p><img src="../../pic/ML/9372381d33584d56600ab575c309b396.jpg" alt="这里写图片描述" /></p>

<h3 id="四-weighted-classification"><strong>四、Weighted Classification</strong></h3>

<p>实际上，机器学习的Cost Function即来自于这些error，也就是算法里面的迭代的目标函数，通过优化使得Error（Ein）不断变小。
cost function中，false accept和false reject赋予不同的权重，在演算法中体现。对不同权重的错误惩罚，可以选用virtual copying的方法。</p>

<p><img src="../../pic/ML/40a94eee7b2d4e550d9af8d1d161e13b.jpg" alt="这里写图片描述" /></p>

<p><img src="../../pic/ML/833bdaad78d2e0081c2546e66738a10f.jpg" alt="这里写图片描述" /></p>

<h3 id="五-总结"><strong>五、总结</strong></h3>

<p>本节课主要讲了在有Noise的情况下，即数据集按照<img src="../../pic/ML/12d12c819c2467c289e4a700f3623212.jpg" alt="" />概率分布，那么VC Dimension仍然成立，机器学习算法推导仍然有效。机器学习cost function常用的Error有0/1 error和squared error两类。实际问题中，对false accept和false reject应该选择不同的权重。</p>

<p><strong><em>注明：</em></strong></p>

<p>文章中所有的图片均来自台湾大学林轩田《机器学习基石》课程。</p>

                </section>
            </article>

            

            
                <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'simeon49';

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';

        
        var disquesLoaded = false;
        dsq.onload = function () {
            disquesLoaded = true;
        };
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);

        setTimeout(() => {
            if (!disquesLoaded) {
                alert('加载disques 失败!');
            }
        }, 3000);

    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

            

            
                <ul id="post-list" class="archive readmore">
    <h3>Read more</h3>

    
    
    
        <li>
            <a href="/blog/posts/2020-01-09-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-%E7%AC%94%E8%AE%B009/">机器学习基石-笔记09<aside class="dates">Jan 9 2020</aside></a>
        </li>
    
        <li>
            <a href="/blog/posts/2020-01-07-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-%E7%AC%94%E8%AE%B007/">机器学习基石-笔记07<aside class="dates">Jan 7 2020</aside></a>
        </li>
    
        <li>
            <a href="/blog/posts/2020-01-06-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-%E7%AC%94%E8%AE%B006/">机器学习基石-笔记06<aside class="dates">Jan 6 2020</aside></a>
        </li>
    
        <li>
            <a href="/blog/posts/2020-01-05-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-%E7%AC%94%E8%AE%B005/">机器学习基石-笔记05<aside class="dates">Jan 5 2020</aside></a>
        </li>
    
        <li>
            <a href="/blog/posts/2020-01-04-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-%E7%AC%94%E8%AE%B004/">机器学习基石-笔记04<aside class="dates">Jan 4 2020</aside></a>
        </li>
    
        <li>
            <a href="/blog/posts/2020-01-03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-%E7%AC%94%E8%AE%B003/">机器学习基石-笔记03<aside class="dates">Jan 3 2020</aside></a>
        </li>
    
        <li>
            <a href="/blog/posts/2020-01-02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-%E7%AC%94%E8%AE%B002/">机器学习基石-笔记02<aside class="dates">Jan 2 2020</aside></a>
        </li>
    
        <li>
            <a href="/blog/posts/2020-01-01-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-%E7%AC%94%E8%AE%B001/">机器学习基石-笔记01<aside class="dates">Jan 1 2020</aside></a>
        </li>
    
        <li>
            <a href="/blog/posts/2019-05-10-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%85%E5%AE%B9%E5%A4%8D%E4%B9%A007-mysql%E7%9A%84%E8%A1%8C%E7%BA%A7%E9%94%81%E5%85%B1%E4%BA%AB%E9%94%81%E4%B8%8E%E6%8E%92%E5%AE%83%E9%94%81/">数据库内容复习07-MySql的行级锁共享锁与排它锁<aside class="dates">May 10 2019</aside></a>
        </li>
    
        <li>
            <a href="/blog/posts/2019-04-12-web-component/">web-component<aside class="dates">Apr 12 2019</aside></a>
        </li>
    
</ul>

            

            <footer id="footer">
    
        <div id="social">

	
	
    <a class="symbol" href="https://github.com/simeon49">
        <i class="fa fa-github-square"></i>
    </a>
    


</div>

    
    <p class="small">
    
       © Copyright 2020 <i class="fa fa-heart" aria-hidden="true"></i> Simeon
    
    </p>
    
</footer>

        </section>

        <script src="https://simeon49.github.io/blog/js/jquery-3.3.1.min.js"></script>
<script src="https://simeon49.github.io/blog/js/main.js"></script>
<script src="https://simeon49.github.io/blog/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>






<script>
var baiduAnalytics = '74fafdde017951e1df78c761e7c017bc';
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?" + baiduAnalytics;
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    </body>
</html>
